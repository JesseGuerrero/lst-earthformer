{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3437e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthformer.cuboid_transformer.cuboid_transformer import CuboidTransformerModel\n",
    "import torch\n",
    "\n",
    "# Optimized config for Landsat 3-timestep forecasting\n",
    "landsat_config = {\n",
    "    'input_shape': (3, 128, 128, 9),    # 3 input timesteps, 128x128, 9 Landsat bands\n",
    "    'target_shape': (3, 128, 128, 1),   # 3 output timesteps\n",
    "    \n",
    "    # Small model for prototyping\n",
    "    'base_units': 96,                    # Small but efficient\n",
    "    'num_heads': 6,                      # Divisible by base_units\n",
    "    'enc_depth': [2, 2],                 # 2-level hierarchy (sufficient for short sequences)\n",
    "    'dec_depth': [1, 1],                 # Matching decoder depth\n",
    "    \n",
    "    # Dropout for better generalization during prototyping\n",
    "    'attn_drop': 0.1,\n",
    "    'proj_drop': 0.1,\n",
    "    'ffn_drop': 0.1,\n",
    "    \n",
    "    # Global vectors for capturing Landsat scene patterns\n",
    "    'num_global_vectors': 8,\n",
    "    'use_dec_self_global': True,\n",
    "    'use_dec_cross_global': True,\n",
    "    \n",
    "    # Optimized for satellite imagery\n",
    "    'pos_embed_type': 't+hw',            # Separate temporal and spatial embeddings\n",
    "    'use_relative_pos': True,            # Good for satellite spatial patterns\n",
    "    'ffn_activation': 'gelu',            # Works well for vision tasks\n",
    "    \n",
    "    # Cuboid settings optimized for short temporal sequences\n",
    "    'enc_cuboid_size': [(2, 4, 4), (2, 4, 4)],     # Small temporal cuboids for 3 timesteps\n",
    "    'enc_cuboid_strategy': [('l', 'l', 'l'), ('d', 'd', 'd')],\n",
    "    \n",
    "    # Cross-attention settings for decoder\n",
    "    'dec_cross_cuboid_hw': [(4, 4), (4, 4)],\n",
    "    'dec_cross_n_temporal': [1, 2],      # Use 1-2 temporal frames for cross-attention\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = CuboidTransformerModel(**landsat_config)\n",
    "print(f\"âœ“ Landsat model created! Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test with dummy Landsat data\n",
    "batch_size = 4  # You can use larger batches with 40GB VRAM\n",
    "dummy_landsat = torch.randn(batch_size, 3, 128, 128, 9)\n",
    "print(f\"Input shape: {dummy_landsat.shape}\")\n",
    "\n",
    "# Forward pass test\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_landsat)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(\"âœ“ Forward pass successful!\")\n",
    "\n",
    "# Memory usage estimate\n",
    "def estimate_memory_usage(model, input_shape, batch_size=1):\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(batch_size, *input_shape)\n",
    "    \n",
    "    # Rough memory estimate\n",
    "    param_memory = sum(p.numel() * 4 for p in model.parameters()) / 1e9  # GB\n",
    "    input_memory = dummy_input.numel() * 4 / 1e9  # GB\n",
    "    \n",
    "    print(f\"Estimated memory usage:\")\n",
    "    print(f\"  Parameters: {param_memory:.2f} GB\")\n",
    "    print(f\"  Input (batch={batch_size}): {input_memory:.2f} GB\")\n",
    "    print(f\"  Activation estimate: ~{param_memory * 2:.2f} GB\")\n",
    "    print(f\"  Total estimate: ~{param_memory * 3 + input_memory:.2f} GB\")\n",
    "\n",
    "estimate_memory_usage(model, (3, 128, 128, 9), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9829c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Running debug training with image visualization...\n",
      "âœ… Found tiled dataset at ./Data/Dataset\n",
      "Testing data module setup...\n",
      "train split: 86 cities, 1351 tile sequences\n",
      "val split: 19 cities, 212 tile sequences\n",
      "âœ… Training batches: 676\n",
      "âœ… Validation batches: 106\n",
      "âœ… Sample batch - Inputs: torch.Size([2, 3, 128, 128, 9]), Targets: torch.Size([2, 3, 128, 128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/earthformer15/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 9,036,109 parameters\n",
      "Testing model with sample data...\n",
      "âœ… Model test - Output shape: torch.Size([2, 3, 128, 128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LANDSAT LST PREDICTION TRAINING - WITH IMAGE VISUALIZATION\n",
      "======================================================================\n",
      "Dataset: ./Data/Dataset\n",
      "Batch size: 2\n",
      "Max epochs: 3\n",
      "Learning rate: 0.001\n",
      "Precision: 32\n",
      "Devices: 1 GPU(s)\n",
      "Experiment: debug_with_images\n",
      "Image logging: Every 1 epochs\n",
      "Max images per log: 2\n",
      "Wandb project: landsat-debug-viz\n",
      "======================================================================\n",
      "\n",
      "ğŸš€ Starting training with image logging...\n",
      "train split: 86 cities, 1351 tile sequences\n",
      "val split: 19 cities, 212 tile sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | CuboidTransformerModel | 9.0 M \n",
      "1 | criterion | MSELoss                | 0     \n",
      "-----------------------------------------------------\n",
      "9.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.0 M     Total params\n",
      "36.144    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cf66d002394a65aa82eba680887ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/earthformer15/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/root/miniconda3/envs/earthformer15/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edb7da2c10547f3a57121467a03c09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a019f233104f4a3996d9519a8d5079d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 6454.605\n",
      "Epoch 0, global step 33: 'val_loss' reached 6454.60498 (best 6454.60498), saving model to './checkpoints/debug_with_images-epoch=00-val_loss=6454.605.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567b64d4eb3c4a08a23ff3249cebbac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 329.479 >= min_delta = 0.0. New best score: 6125.126\n",
      "Epoch 0, global step 66: 'val_loss' reached 6125.12598 (best 6125.12598), saving model to './checkpoints/debug_with_images-epoch=00-val_loss=6125.126.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727f8bb142fb4f1fb1f92189c2194340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 380.510 >= min_delta = 0.0. New best score: 5744.616\n",
      "Epoch 1, global step 100: 'val_loss' reached 5744.61572 (best 5744.61572), saving model to './checkpoints/debug_with_images-epoch=01-val_loss=5744.616.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369e53336a384a4abfcd8fafe69092e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 408.777 >= min_delta = 0.0. New best score: 5335.839\n",
      "Epoch 1, global step 133: 'val_loss' reached 5335.83887 (best 5335.83887), saving model to './checkpoints/debug_with_images-epoch=01-val_loss=5335.839.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82091b0ad6f847bca04bcaa8f91e1e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 444.283 >= min_delta = 0.0. New best score: 4891.556\n",
      "Epoch 2, global step 167: 'val_loss' reached 4891.55566 (best 4891.55566), saving model to './checkpoints/debug_with_images-epoch=02-val_loss=4891.556.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5d05b6c7884e04b1719444f523ece4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 463.529 >= min_delta = 0.0. New best score: 4428.026\n",
      "Epoch 2, global step 200: 'val_loss' reached 4428.02637 (best 4428.02637), saving model to './checkpoints/debug_with_images-epoch=02-val_loss=4428.026.ckpt' as top 3\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "Restoring states from the checkpoint path at ./checkpoints/debug_with_images-epoch=02-val_loss=4428.026.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª Running final test...\n",
      "test split: 19 cities, 0 tile sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/earthformer15/lib/python3.10/site-packages/pytorch_lightning/utilities/cloud_io.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ./checkpoints/debug_with_images-epoch=02-val_loss=4428.026.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test completed: []\n",
      "\n",
      "ğŸ‰ Training completed successfully!\n",
      "ğŸ“ Best model saved to: ./checkpoints/debug_with_images-epoch=02-val_loss=4428.026.ckpt\n",
      "ğŸ”— View experiment with images at: https://wandb.ai/jesus-guerrero-ml/landsat-lst-forecasting/runs/p7gmy923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/earthformer15/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:153: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–â–â–â–â–â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–…â–…â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>lr-AdamW</td><td>â–â–â–â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss_epoch</td><td>â–‡â–„â–â–ˆâ–†â–…</td></tr><tr><td>train_loss_step</td><td>â–…â–†â–ˆâ–†â–…â–†â–„â–…â–…â–‡â–†â–†â–„â–…â–„â–…â–…â–…â–ƒâ–„â–…â–„â–…â–‚â–…â–‚â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–â–‚â–â–ˆâ–ˆâ–†</td></tr><tr><td>train_mae_epoch</td><td>â–‡â–„â–â–ˆâ–†â–…</td></tr><tr><td>train_mae_step</td><td>â–†â–†â–ˆâ–†â–…â–‡â–„â–†â–…â–‡â–‡â–†â–…â–…â–…â–…â–†â–…â–„â–…â–†â–…â–†â–ƒâ–…â–ƒâ–…â–…â–ƒâ–‚â–„â–„â–‚â–ƒâ–â–ƒâ–‚â–ˆâ–ˆâ–‡</td></tr><tr><td>train_temp_mae_scaled</td><td>â–‡â–„â–â–ˆâ–†â–…</td></tr><tr><td>train_temp_rmse_scaled</td><td>â–‡â–„â–â–ˆâ–†â–…</td></tr><tr><td>trainer/global_step</td><td>â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>val_correlation</td><td>â–ˆâ–ˆâ–ˆâ–â–†â–ƒâ–…â–†â–ˆ</td></tr><tr><td>val_loss</td><td>â–‡â–„â–â–ˆâ–‡â–‡â–†â–…â–…</td></tr><tr><td>val_mae</td><td>â–ˆâ–…â–â–ˆâ–ˆâ–‡â–†â–†â–…</td></tr><tr><td>val_temp_mae_scaled</td><td>â–ˆâ–…â–â–ˆâ–ˆâ–‡â–†â–†â–…</td></tr><tr><td>val_temp_rmse_scaled</td><td>â–‡â–…â–â–ˆâ–ˆâ–‡â–†â–†â–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>lr-AdamW</td><td>0.001</td></tr><tr><td>train_loss_epoch</td><td>9112.23047</td></tr><tr><td>train_loss_step</td><td>11278.71875</td></tr><tr><td>train_mae_epoch</td><td>93.66899</td></tr><tr><td>train_mae_step</td><td>106.0422</td></tr><tr><td>train_temp_mae_scaled</td><td>93.66899</td></tr><tr><td>train_temp_rmse_scaled</td><td>94.97568</td></tr><tr><td>trainer/global_step</td><td>200</td></tr><tr><td>val_correlation</td><td>0.27445</td></tr><tr><td>val_loss</td><td>4428.02637</td></tr><tr><td>val_mae</td><td>65.22322</td></tr><tr><td>val_temp_mae_scaled</td><td>65.22322</td></tr><tr><td>val_temp_rmse_scaled</td><td>66.39657</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">debug_viz</strong> at: <a href='https://wandb.ai/jesus-guerrero-ml/landsat-lst-forecasting/runs/p7gmy923' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/landsat-lst-forecasting/runs/p7gmy923</a><br> View project at: <a href='https://wandb.ai/jesus-guerrero-ml/landsat-lst-forecasting' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/landsat-lst-forecasting</a><br>Synced 5 W&B file(s), 51 media file(s), 12 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./logs/wandb/run-20250701_043440-p7gmy923/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from model import LandsatLSTPredictor  # Your enhanced model\n",
    "from dataset import LandsatDataModule\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "def train_landsat_model_with_images(\n",
    "    dataset_root: str = \"./Data/Dataset\",\n",
    "    batch_size: int = 4,\n",
    "    max_epochs: int = 100,\n",
    "    learning_rate: float = 1e-4,\n",
    "    num_workers: int = 4,\n",
    "    gpus: int = 1,\n",
    "    precision: str = \"32\",\n",
    "    accumulate_grad_batches: int = 1,\n",
    "    val_check_interval: float = 1.0,\n",
    "    limit_train_batches: float = 1.0,\n",
    "    limit_val_batches: float = 1.0,\n",
    "    experiment_name: str = \"landsat_lst_prediction_with_viz\",\n",
    "    checkpoint_dir: str = \"./checkpoints\",\n",
    "    log_dir: str = \"./logs\",\n",
    "    wandb_project: str = \"landsat-lst-forecasting\",\n",
    "    wandb_tags: list = None,\n",
    "    log_images_every_n_epochs: int = 5,\n",
    "    max_images_to_log: int = 4\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced training pipeline with WandB image logging\n",
    "    \n",
    "    Args:\n",
    "        log_images_every_n_epochs: How often to log images (every N epochs)\n",
    "        max_images_to_log: Maximum number of samples to visualize per batch\n",
    "    \"\"\"\n",
    "    \n",
    "    if wandb_tags is None:\n",
    "        wandb_tags = [\"landsat\", \"lst-prediction\", \"earthformer\", \"with-viz\"]\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Verify dataset\n",
    "    dataset_path = os.path.join(dataset_root)\n",
    "    cities_tiles = os.path.join(dataset_path, \"Cities_Tiles\")\n",
    "    dem_tiles = os.path.join(dataset_path, \"DEM_2014_Tiles\")\n",
    "    \n",
    "    if not os.path.exists(cities_tiles):\n",
    "        raise FileNotFoundError(f\"Cities_Tiles directory not found at {cities_tiles}\")\n",
    "    if not os.path.exists(dem_tiles):\n",
    "        raise FileNotFoundError(f\"DEM_2014_Tiles directory not found at {dem_tiles}\")\n",
    "    \n",
    "    print(f\"âœ… Found tiled dataset at {dataset_root}\")\n",
    "    \n",
    "    # Initialize data module\n",
    "    data_module = LandsatDataModule(\n",
    "        dataset_root=dataset_root,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        sequence_length=3\n",
    "    )\n",
    "    \n",
    "    # Test data module\n",
    "    print(\"Testing data module setup...\")\n",
    "    try:\n",
    "        data_module.setup(\"fit\")\n",
    "        train_loader = data_module.train_dataloader()\n",
    "        val_loader = data_module.val_dataloader()\n",
    "        \n",
    "        print(f\"âœ… Training batches: {len(train_loader)}\")\n",
    "        print(f\"âœ… Validation batches: {len(val_loader)}\")\n",
    "        \n",
    "        # Test one batch\n",
    "        sample_batch = next(iter(train_loader))\n",
    "        inputs, targets = sample_batch\n",
    "        print(f\"âœ… Sample batch - Inputs: {inputs.shape}, Targets: {targets.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Data module test failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Enhanced config for wandb\n",
    "    config = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_epochs\": max_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_workers\": num_workers,\n",
    "        \"precision\": precision,\n",
    "        \"accumulate_grad_batches\": accumulate_grad_batches,\n",
    "        \"val_check_interval\": val_check_interval,\n",
    "        \"limit_train_batches\": limit_train_batches,\n",
    "        \"limit_val_batches\": limit_val_batches,\n",
    "        \"dataset_root\": dataset_root,\n",
    "        \"model_type\": \"CuboidTransformer\",\n",
    "        \"input_shape\": [3, 128, 128, 9],\n",
    "        \"target_shape\": [3, 128, 128, 1],\n",
    "        \"sequence_length\": 3,\n",
    "        \"train_batches\": len(train_loader),\n",
    "        \"val_batches\": len(val_loader),\n",
    "        \"total_train_samples\": len(train_loader) * batch_size,\n",
    "        \"total_val_samples\": len(val_loader) * batch_size,\n",
    "        \"log_images_every_n_epochs\": log_images_every_n_epochs,\n",
    "        \"max_images_to_log\": max_images_to_log,\n",
    "        \"band_names\": ['DEM', 'LST', 'Red', 'Green', 'Blue', 'NDVI', 'NDWI', 'NDBI', 'Albedo']\n",
    "    }\n",
    "    \n",
    "    # Initialize Weights & Biases logger\n",
    "    logger = WandbLogger(\n",
    "        project=wandb_project,\n",
    "        name=experiment_name,\n",
    "        tags=wandb_tags,\n",
    "        config=config,\n",
    "        save_dir=log_dir,\n",
    "        log_model=True,\n",
    "    )\n",
    "    \n",
    "    # Initialize enhanced model with image logging\n",
    "    model = LandsatLSTPredictor(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=1e-5,\n",
    "        warmup_steps=1000,\n",
    "        max_epochs=max_epochs,\n",
    "        log_images_every_n_epochs=log_images_every_n_epochs,\n",
    "        max_images_to_log=max_images_to_log\n",
    "    )\n",
    "    \n",
    "    # Test model\n",
    "    print(\"Testing model with sample data...\")\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_output = model(inputs)\n",
    "            print(f\"âœ… Model test - Output shape: {test_output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Model test failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=checkpoint_dir,\n",
    "        filename=f'{experiment_name}-{{epoch:02d}}-{{val_loss:.3f}}',\n",
    "        save_top_k=3,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_last=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    \n",
    "    # Trainer configuration\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator='gpu' if gpus > 0 else 'cpu',\n",
    "        devices=gpus if gpus > 0 else None,\n",
    "        accumulate_grad_batches=accumulate_grad_batches,\n",
    "        val_check_interval=val_check_interval,\n",
    "        limit_train_batches=limit_train_batches,\n",
    "        limit_val_batches=limit_val_batches,\n",
    "        callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "        logger=logger,\n",
    "        log_every_n_steps=50,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        deterministic=False,\n",
    "        benchmark=True,\n",
    "    )\n",
    "    \n",
    "    # Print training info\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"LANDSAT LST PREDICTION TRAINING - WITH IMAGE VISUALIZATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Dataset: {dataset_root}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Max epochs: {max_epochs}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Devices: {gpus} GPU(s)\" if gpus > 0 else \"CPU\")\n",
    "    print(f\"Experiment: {experiment_name}\")\n",
    "    print(f\"Image logging: Every {log_images_every_n_epochs} epochs\")\n",
    "    print(f\"Max images per log: {max_images_to_log}\")\n",
    "    print(f\"Wandb project: {wandb_project}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Train the model\n",
    "    try:\n",
    "        print(\"ğŸš€ Starting training with image logging...\")\n",
    "        trainer.fit(model, data_module)\n",
    "        \n",
    "        # Test the model\n",
    "        print(\"\\nğŸ§ª Running final test...\")\n",
    "        try:\n",
    "            test_results = trainer.test(model, data_module, ckpt_path='best')\n",
    "            print(f\"âœ… Test completed: {test_results}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Test failed: {e}\")\n",
    "        \n",
    "        print(f\"\\nğŸ‰ Training completed successfully!\")\n",
    "        print(f\"ğŸ“ Best model saved to: {checkpoint_callback.best_model_path}\")\n",
    "        print(f\"ğŸ”— View experiment with images at: {logger.experiment.url}\")\n",
    "        \n",
    "        # Log final artifacts\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            wandb.save(checkpoint_callback.best_model_path)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸ Training interrupted by user\")\n",
    "        print(f\"ğŸ“ Last checkpoint: {checkpoint_callback.last_model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        if 'logger' in locals():\n",
    "            wandb.log({\"error\": str(e)})\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        if 'logger' in locals():\n",
    "            wandb.finish()\n",
    "    \n",
    "    return trainer, model, data_module\n",
    "\n",
    "\n",
    "def debug_with_images(dataset_root: str = \"./Data/Dataset\"):\n",
    "    \"\"\"Debug run with image logging\"\"\"\n",
    "    print(\"ğŸ”§ Running debug training with image visualization...\")\n",
    "    \n",
    "    return train_landsat_model_with_images(\n",
    "        dataset_root=dataset_root,\n",
    "        batch_size=2,\n",
    "        max_epochs=3,\n",
    "        learning_rate=1e-3,\n",
    "        num_workers=0,\n",
    "        gpus=1,\n",
    "        precision=\"32\",\n",
    "        limit_train_batches=0.1,\n",
    "        limit_val_batches=0.1,\n",
    "        experiment_name=\"debug_with_images\",\n",
    "        val_check_interval=0.5,\n",
    "        wandb_project=\"landsat-debug-viz\",\n",
    "        wandb_tags=[\"debug\", \"visualization\", \"landsat\"],\n",
    "        log_images_every_n_epochs=1,  # Log every epoch for debugging\n",
    "        max_images_to_log=2\n",
    "    )\n",
    "\n",
    "\n",
    "def full_training_with_viz(dataset_root: str = \"./Data/Dataset\"):\n",
    "    \"\"\"Full training with image visualization\"\"\"\n",
    "    print(\"ğŸš€ Starting full training with visualization...\")\n",
    "    \n",
    "    return train_landsat_model_with_images(\n",
    "        dataset_root=dataset_root,\n",
    "        batch_size=8,\n",
    "        max_epochs=50,\n",
    "        learning_rate=2e-4,\n",
    "        num_workers=4,\n",
    "        gpus=1,\n",
    "        precision=\"16-mixed\",\n",
    "        experiment_name=\"landsat_full_training_with_viz\",\n",
    "        val_check_interval=1.0,\n",
    "        wandb_project=\"landsat-lst-forecasting\",\n",
    "        wandb_tags=[\"full-training\", \"visualization\", \"earthformer\", \"gpu\"],\n",
    "        log_images_every_n_epochs=5,  # Log images every 5 epochs\n",
    "        max_images_to_log=4\n",
    "    )\n",
    "\n",
    "\n",
    "# Additional utility function for creating sample visualizations\n",
    "def create_sample_visualization(dataset_root: str = \"./Data/Dataset\"):\n",
    "    \"\"\"Create and log a sample visualization without training\"\"\"\n",
    "    from dataset import LandsatDataModule\n",
    "    import matplotlib.pyplot as plt\n",
    "    import wandb\n",
    "    \n",
    "    print(\"ğŸ“Š Creating sample visualization...\")\n",
    "    \n",
    "    # Initialize wandb for standalone visualization\n",
    "    wandb.init(\n",
    "        project=\"landsat-sample-viz\",\n",
    "        name=\"sample_tiles_preview\",\n",
    "        tags=[\"sample\", \"preview\", \"no-training\"]\n",
    "    )\n",
    "    \n",
    "    # Load sample data\n",
    "    data_module = LandsatDataModule(\n",
    "        dataset_root=dataset_root,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        sequence_length=3\n",
    "    )\n",
    "    \n",
    "    data_module.setup(\"fit\")\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    \n",
    "    # Get one batch\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    inputs, targets = sample_batch\n",
    "    \n",
    "    print(f\"Sample data shapes - Inputs: {inputs.shape}, Targets: {targets.shape}\")\n",
    "    \n",
    "    # Create temporary model for visualization methods\n",
    "    temp_model = LandsatLSTPredictor()\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig1 = temp_model.create_landsat_visualization(inputs, targets, None, 0, 4)\n",
    "    fig2 = temp_model.create_temporal_sequence_viz(inputs, targets, None, 0)\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"sample_landsat_tiles\": wandb.Image(fig1, caption=\"Sample Landsat Tiles\"),\n",
    "        \"sample_temporal_sequence\": wandb.Image(fig2, caption=\"Sample Temporal Sequence\")\n",
    "    })\n",
    "    \n",
    "    plt.close(fig1)\n",
    "    plt.close(fig2)\n",
    "    \n",
    "    print(\"âœ… Sample visualization created and logged to WandB!\")\n",
    "    print(f\"ğŸ”— View at: {wandb.run.url}\")\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Then add this function to your training script:\n",
    "def train_with_visualization(\n",
    "    dataset_root: str = \"./Data/Dataset\",\n",
    "    batch_size: int = 4,\n",
    "    max_epochs: int = 50,\n",
    "    learning_rate: float = 2e-4,\n",
    "    num_workers: int = 4,\n",
    "    gpus: int = 1,\n",
    "    experiment_name: str = \"landsat_with_viz\",\n",
    "    log_images_every_n_epochs: int = 5,\n",
    "    max_images_to_log: int = 4\n",
    "):\n",
    "    \"\"\"Enhanced training with visualization\"\"\"\n",
    "    \n",
    "    # Your existing data module setup\n",
    "    data_module = LandsatDataModule(\n",
    "        dataset_root=dataset_root,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        sequence_length=3\n",
    "    )\n",
    "    \n",
    "    # Enhanced WandB logger\n",
    "    logger = WandbLogger(\n",
    "        project=\"landsat-lst-forecasting\",\n",
    "        name=experiment_name,\n",
    "        tags=[\"earthformer\", \"visualization\", \"landsat\"],\n",
    "        save_dir=\"./logs\",\n",
    "        log_model=True,\n",
    "    )\n",
    "    \n",
    "    # Enhanced model with visualization\n",
    "    model = LandsatLSTPredictor(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=1e-5,\n",
    "        warmup_steps=1000,\n",
    "        max_epochs=max_epochs,\n",
    "        log_images_every_n_epochs=log_images_every_n_epochs,\n",
    "        max_images_to_log=max_images_to_log\n",
    "    )\n",
    "    \n",
    "    # Your existing callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"./checkpoints\",\n",
    "        filename=f'{experiment_name}-{{epoch:02d}}-{{val_loss:.3f}}',\n",
    "        save_top_k=3,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_last=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    \n",
    "    # Your existing trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator='gpu' if gpus > 0 else 'cpu',\n",
    "        devices=gpus if gpus > 0 else None,\n",
    "        callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "        logger=logger,\n",
    "        log_every_n_steps=50,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "    )\n",
    "    \n",
    "    # Train as usual\n",
    "    trainer.fit(model, data_module)\n",
    "    \n",
    "    return trainer, model, data_module\n",
    "\n",
    "# Quick debug function\n",
    "def debug_visualization():\n",
    "    \"\"\"Quick test with image logging\"\"\"\n",
    "    return train_with_visualization(\n",
    "        batch_size=2,\n",
    "        max_epochs=3,\n",
    "        experiment_name=\"debug_viz\",\n",
    "        log_images_every_n_epochs=1,  # Log every epoch for debugging\n",
    "        max_images_to_log=2\n",
    "    )\n",
    "\n",
    "def test_visualization_only():\n",
    "    \"\"\"Just create sample visualizations to test\"\"\"\n",
    "    from dataset import LandsatDataModule\n",
    "    \n",
    "    # Initialize wandb for testing\n",
    "    wandb.init(project=\"landsat-viz-test\", name=\"test_viz\")\n",
    "    \n",
    "    # Load sample data\n",
    "    data_module = LandsatDataModule(\n",
    "        dataset_root=\"./Data/Dataset\",\n",
    "        batch_size=2,\n",
    "        num_workers=0\n",
    "    )\n",
    "    data_module.setup(\"fit\")\n",
    "    \n",
    "    # Get one batch\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    inputs, targets = next(iter(train_loader))\n",
    "    \n",
    "    # Create model just for visualization\n",
    "    model = LandsatLSTPredictor()\n",
    "    \n",
    "    # Create dummy predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(inputs)\n",
    "    \n",
    "    # Test visualization\n",
    "    fig = model.create_landsat_visualization(inputs, targets, predictions)\n",
    "    wandb.log({\"test_visualization\": wandb.Image(fig)})\n",
    "    \n",
    "    plt.close(fig)\n",
    "    wandb.finish()\n",
    "    print(\"âœ… Test visualization created and logged to WandB!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # test_visualization_only()\n",
    "    # debug_visualization()\n",
    "\n",
    "    # For debugging with image logging:\n",
    "    debug_with_images()\n",
    "    \n",
    "    # For full training with visualization:\n",
    "    # full_training_with_viz()\n",
    "    \n",
    "    # For just creating sample visualizations:\n",
    "    # create_sample_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab6da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthformer15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
